{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungszettel 9: Regression, Gradient Descent\n",
    "\n",
    "## Maschinelles Lernen - WiSe 23/24\n",
    "\n",
    "### Abgabe 03.01.2024, 23:55 Uhr\n",
    "\n",
    "*Hinweise:*\n",
    "- Übungsaufgaben **müssen** in Gruppen von 3-4 Personen abgegeben werden. **Einzelabgaben werden nicht korrigiert bzw. bewertet.**\n",
    "- Es wird pro Übungszettel nur eine Aufgabe bewertet, die übrigen Aufgaben dienen zur selbstständigen Vertiefung des Vorlesungsstoffs. Für diese Aufgaben werden nach der Abgabe Musterlösungen bereitgestellt.\n",
    "- Die Lösungen sollen in diesem IPython Notebook realisiert werden, wobei Teilaufgaben und Zwischenergebnisse ausgegeben bzw. visualisiert werden sollen.\n",
    "- Für die Abgabe sollen Sie dieses IPython Notebook und ggf. zugehörige Dateien in ein **Ziparchiv** packen und im Ilias hochladen. Das Ziparchiv soll nach folgendem Muster benannt werden:\n",
    "`UebungXX_Nachname1_Nachname2_Nachname3.zip`, wobei die Nachnamen in alphabetischer Reihenfolge angegeben und Umlaute ggf. ersetzt werden sollen. Bei Nichtbefolgung dieser Vorgabe können Punkte abgezogen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Aufgabe 1: Regression\n",
    "\n",
    "Erklären Sie kurz (mit wenigen Sätzen) die folgenden Begriffe:\n",
    "\n",
    "* Methode der kleinsten Quadrate (Least squares)\n",
    "* Gradientenabstieg (Gradien Descent)\n",
    "* Normal Equation\n",
    "* Kostenfunktion\n",
    "* Gradient Check\n",
    "* Multiple lineare Regression (Multivariate Linear Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mittel wert 2.058333333333333\n",
      "Varianz 80.15901515151515\n",
      "schiefe 0.0005401118211730421\n"
     ]
    }
   ],
   "source": [
    "list = [-4,1,-0.3,-7,-14,9,-1,22,3.5,4,3.5,8]\n",
    "\n",
    "n = len(list)\n",
    "# berechne emperische mittelwert von list\n",
    "sum = 0\n",
    "for i in list:\n",
    "    sum += i\n",
    "mittel_wert = sum/len(list)    \n",
    "print('mittel wert', mittel_wert)\n",
    "\n",
    "# berechne emperische Varianz von list\n",
    "sum = 0\n",
    "for i in list:\n",
    "    sum += (i - mittel_wert)**2\n",
    "varianz = sum/(n-1)\n",
    "print('Varianz', varianz)\n",
    "\n",
    "# berechne emperische schiefe der stichprobe\n",
    "\n",
    "skew = 0\n",
    "for i in list:\n",
    "    skew += ((i - mittel_wert)/varianz)**3\n",
    "skew = skew/n\n",
    "print('schiefe', skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Aufgabe 2: Gradient Descent (bewertet: 1,5+1+1+1+0,5 Punkte)**\n",
    "In dieser Aufgabe sollen Sie das Gradientenabstiegsverfahren zur Minimierung der folgenden Funktion $f(u)$ anwenden:\n",
    "$$ f(u) = \\frac{(u-10)^4}{4} + (u-10)^3 + 50 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Führen Sie das Gradientenabstiegsverfahren für **5 Iterationen** von Hand durch und geben Sie nach jedem Schritt den Wert von $u$ an.\n",
    "\n",
    "Verwenden Sie als Parameter\n",
    "* Lernrate $\\alpha=0.05$ \n",
    "* Startpunkt $u=13$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Hier können Sie Ihre Lösung in } \\mathrm{L\\!\\!^{{}_{A}} \\!\\!\\!\\!\\!\\;\\; T\\!_{\\displaystyle E} \\! X} \\text{ einfügen...} $$\n",
    "\n",
    "![Bild](https://via.placeholder.com/500x80?text=...oder+ein+Bild+einbinden.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Das Gradientenabstiegsverfahren mit Momentum ist eine Modifikation des Gradientenabstiegsverfahrens, \n",
    "bei dem statt der direkten Aktualisierung der Parameter zunächst ein Momentums-Vektor $\\Delta$ aktualisiert wird, \n",
    "der nicht nur vom Gradienten, sondern auch dem Momentum der letzten Iteration abhängt. \n",
    "Dabei wird über den Parameter $\\mu$ gesteuert, wie stark das Momentum gewichtet wird.\n",
    "\n",
    "$\\Delta := - \\alpha \\frac{\\partial}{\\partial u} f(u)+ \\mu \\Delta$\n",
    "\n",
    "Der Momentums-Vektor wird nun verwendet, um $u$ zu aktualisieren. Die Update-Regel ändert sich damit zu\n",
    "\n",
    "$u := u + \\Delta $\n",
    "\n",
    "---\n",
    "\n",
    "Führen Sie dieses modifizierte Verfahren für **5 Iterationen** durch, um die Funktion $f$ zu minimieren.\n",
    "Geben Sie nach jedem Schritt die Werte von $u$ und $\\Delta$ an.\n",
    "\n",
    "Verwenden Sie dabei als Parameter\n",
    "* Lernrate $\\alpha=0.05$\n",
    "* Momentums-Parameter $\\mu=0.5$\n",
    "* Startpunkt $u=13$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Hier können Sie Ihre Lösung in } \\mathrm{L\\!\\!^{{}_{A}} \\!\\!\\!\\!\\!\\;\\; T\\!_{\\displaystyle E} \\! X} \\text{ einfügen...} $$\n",
    "\n",
    "![Bild](https://via.placeholder.com/500x80?text=...oder+ein+Bild+einbinden.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Plotten Sie den Funktionsverlauf der Funktion $f$ für das Intervall $[5, 13]$ und zeichnen Sie die in Aufgabenteil a) und b) nach 5 Iterationen bestimmten Werte von $u$ ein. \n",
    "\n",
    "Wird in beiden Fällen das Minimum gefunden? Wenn nein, wieso nicht?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implementieren sie das Gradientenabstiegsverfahren mit Momentum zur Bestimmung des Minimums der Funktion $f$ in Python. \n",
    "\n",
    "*Hinweis: Verwenden Sie in dieser Aufgabe keine Bibliotheken außer Numpy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Führen Sie mit Ihrer Implementierung das Gradientenabstiegsverfahren mit den in Aufgabenteil b) gegebenen Parametern für **50 Iterationen** durch. \n",
    "Plotten Sie erneut die Funktion $f$ und zeichnen Sie das ermittelte Minimum ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
