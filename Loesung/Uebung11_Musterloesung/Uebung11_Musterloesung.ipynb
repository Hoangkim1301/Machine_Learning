{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungszettel 11: SVM und Backpropagation (Musterlösung)\n",
    "\n",
    "## Maschinelles Lernen - WiSe 23/24\n",
    "\n",
    "### Abgabe 24.01.2024, 23:55 Uhr\n",
    "\n",
    "*Hinweise:*\n",
    "- Übungsaufgaben **müssen** in Gruppen von 3-4 Personen abgegeben werden. **Einzelabgaben werden nicht korrigiert bzw. bewertet.**\n",
    "- Es wird pro Übungszettel nur eine Aufgabe bewertet, die übrigen Aufgaben dienen zur selbstständigen Vertiefung des Vorlesungsstoffs. Für diese Aufgaben werden nach der Abgabe Musterlösungen bereitgestellt.\n",
    "- Die Lösungen sollen in diesem IPython Notebook realisiert werden, wobei Teilaufgaben und Zwischenergebnisse ausgegeben bzw. visualisiert werden sollen.\n",
    "- Für die Abgabe sollen Sie dieses IPython Notebook und ggf. zugehörige Dateien in ein **Ziparchiv** packen und im Ilias hochladen. Das Ziparchiv soll nach folgendem Muster benannt werden:\n",
    "`UebungXX_Nachname1_Nachname2_Nachname3.zip`, wobei die Nachnamen in alphabetischer Reihenfolge angegeben und Umlaute ggf. ersetzt werden sollen. Bei Nichtbefolgung dieser Vorgabe können Punkte abgezogen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aufgabe 1: SVM\n",
    "\n",
    "In den folgenden Aufgabenteilen soll mit Hilfe der Stützvektormethode (SVM) die durch die Geradengleichung $w_1x_1 + w_2x_2 = t$ mit maximalem Rand definierte lineare Diskriminanzfunktion von Hand berechnet werden.\n",
    "\n",
    "Gegeben seien die folgenden 2-dimensionalen Datenpunkte $\\mathbf{X}$ mit Klasse $\\mathbf{y}$:\n",
    "\n",
    "|$x_1$|$x_2$|$y$|\n",
    "|:----|:----|:--|\n",
    "|  1  |  3  | -1|\n",
    "| −1  |  3  | -1|\n",
    "| −1  | −1  | +1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Stellen Sie das duale Optimierungsproblem für die gegebenen Punkte auf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duales Problem mit Lagrange-Multiplikatoren:\n",
    "\n",
    "$\\max_\\alpha \\sum_{i=1}^m \\alpha_i - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y^{(i)} y^{(j)} x^{(i)^T} x^{(j)} $\n",
    "\n",
    "$s. t. \\alpha_i \\geq 0$ $\\forall i = 1, \\dots, m$ und $0 = \\sum_{i=1}^m \\alpha_i y^{(i)}$\n",
    "\n",
    "Einsetzen der Trainingsbeispiele ergibt:\n",
    "\n",
    "$\\max_\\alpha \\sum_{i=1}^m \\alpha_i - \\frac{1}{2} \\left ( \\alpha_1 \\alpha_1 \\begin{pmatrix} 1 & 3 \\end{pmatrix} \\begin{pmatrix} 1\\\\3 \\end{pmatrix} + \\dots + \\alpha_3 \\alpha_3 \\begin{pmatrix} -1 & -1 \\end{pmatrix} \\begin{pmatrix} -1\\\\-1 \\end{pmatrix} \\right ) $\n",
    "\n",
    "$= \\max_\\alpha \\alpha_1 + \\alpha_2 + \\alpha_3 - 5 \\alpha_1^2 - 5 \\alpha_2^2 - \\alpha_3^2 - 8 \\alpha_1 \\alpha_2 - 4 \\alpha_1 \\alpha_3 - 2 \\alpha_2 \\alpha_3$\n",
    "\n",
    "Und für die Nebenbedingung:\n",
    "\n",
    "$0 = - \\alpha_1 - \\alpha_2 + \\alpha_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In der Praxis werden solche dualen Optimierungsprobleme mit quadratischer Programmierung gelöst. Hier soll es aber von Hand gelöst werden. Gehen Sie wie folgt vor:\n",
    "\n",
    "* Nutzen Sie die Nebenbedingungen, um $\\alpha_3$ zu eliminieren\n",
    "* Berechnen Sie $\\alpha_1$, $\\alpha_2$ und schließlich $\\alpha_3$\n",
    "* Berechnen Sie $\\mathbf{w}$\n",
    "* Bestimmen Sie die Breite des maximalen Randes (maximum margin)\n",
    "* Geben Sie die Stützvektoren (support vectors) an\n",
    "* Berechnen Sie $t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Berechnen von $\\alpha_1, \\alpha_2, \\alpha_3$ : \n",
    "$0 = - \\alpha_1 - \\alpha_2 + \\alpha_3 \\\\\n",
    "\\Rightarrow \\alpha_3 = \\alpha_1 + \\alpha_2$\n",
    "Somit kann die Nebenbedingung in das Optimierungsproblem eingesetzt werden:\n",
    "\n",
    "$max_\\alpha \\alpha_1 + \\alpha_2 + \\alpha_1 + \\alpha_2 - 5 \\alpha_1^2 - 5 \\alpha_2^2 - (\\alpha_1 + \\alpha_2)^2 - 8 \\alpha_1 \\alpha_2 - 4 \\alpha_1 (\\alpha_1 + \\alpha_2) - 2 \\alpha_2 (\\alpha_1 + \\alpha_2) \\\\\n",
    "= max_\\alpha 2 \\alpha_1 + 2 \\alpha_2 - 10 \\alpha_1^2 - 8 \\alpha_2^2 - 16 \\alpha_1 \\alpha_2 \\\\\n",
    "= max_\\alpha \\alpha_1 + \\alpha_2 - 5 \\alpha_1^2 - 4 \\alpha_2^2 - 8 \\alpha_1 \\alpha_2 $\n",
    "\n",
    "Wir berechnen die partiellen Ableitungen nach $\\alpha_1$ und $\\alpha_2$ und setzen diese = 0 um das Maximum zu finden:\n",
    "\n",
    "$0=1-10\\alpha_1-8\\alpha_2$\n",
    "\n",
    "$0=1-8\\alpha_2-8\\alpha_1$\n",
    "\n",
    "$\\Rightarrow max = \\frac{1}{16}$ bei $\\alpha_1 = 0$ und $\\alpha_2 = \\frac{1}{8}$\n",
    "\n",
    "$\\Rightarrow \\alpha_3 = \\frac{1}{8} $\n",
    "\n",
    "####  Gewichtsvektor $\\mathbf{w}$ berechnen:\n",
    "$\\mathbf{w} = \\sum_{i=1}^3 \\alpha_i y^{(i)} x^{(i)} = \\frac{1}{8} y^{(2)} x^{(2)} + \\frac{1}{8} y^{(3)} x^{(3)} \\\\ \n",
    "= \\frac{1}{8} \\left ( \\begin{pmatrix}-1\\\\-1\\end{pmatrix} - \\begin{pmatrix}-1\\\\3\\end{pmatrix} \\right )\n",
    "= \\begin{pmatrix} 0 \\\\ - \\frac{1}{2} \\end{pmatrix}$\n",
    "\n",
    "#### Maximum Margin bestimmen:\n",
    "\n",
    "Länge von $\\mathbf{w}$:\n",
    "\n",
    "$||\\mathbf{w}|| = \\sqrt{w_1^2 + w_2^2} = \\sqrt{(- \\frac{1}{2})^2} = \\frac{1}{2}$\n",
    "\n",
    "Die Margin ist also $\\frac{1}{||\\mathbf{w}||} = 2$\n",
    "\n",
    "#### Stützvektoren bestimmen:\n",
    "\n",
    "Supportvektoren sind alle Eingabevektoren $x^{(i)}$, für die gilt $\\alpha_i \\neq 0$, also $x^{(2)}$ und $x^{(3)}$.\n",
    "\n",
    "#### $t$ bestimmen:\n",
    "\n",
    "Da wir einen Hard Margin haben, können wir nun anhand eines Supportvektors auch $b$ bzw. $t$ bestimmen:\n",
    "\n",
    "$y^{(2)} (w^T x^{(2)}-t) = 1$\n",
    "\n",
    "$\\Rightarrow - \\begin{pmatrix}0&-0.5\\end{pmatrix} \\begin{pmatrix}-1\\\\3\\end{pmatrix} +t = 1$\n",
    "\n",
    "$\\Rightarrow 1.5 +t = 1 \\Rightarrow t = -0.5$\n",
    "\n",
    "#### Diskriminanzfunktion:\n",
    "\n",
    "Mit den Parametern ergibt sich eine Gerade, die durch $y=1$ verläuft. Die Diskriminanzfunktion ist also:\n",
    "\n",
    "$K(x) =\\textrm{sgn} \\left ( \\sum_{i=1}^m \\alpha_i y^{(i)} x^{(i)^T} x -t \\right ) \\\\\n",
    "=\\textrm{sgn} \\left ( y^{(2)} x^{(2)^T} x + y^{(3)} x^{(3)^T} x + 0.5 \\right )  \\\\\n",
    "=\\textrm{sgn} \\left ( \\begin{pmatrix} -1 & -1 \\end{pmatrix} x - \\begin{pmatrix} -1 & 3 \\end{pmatrix} x +  0.5 \\right )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Wenden Sie nun die in b) berechnete Diskriminanzfunktion auf den Punkt $ \\mathbf{x}=\\begin{bmatrix} 3 \\\\ 0 \\\\ \\end{bmatrix} $ an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K(\\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix}) = \\textrm{sgn} \\left ( \\begin{pmatrix} -1 & -1 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} -1 & 3 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix} +  0.5 \\right ) \\\\\n",
    "= \\textrm{sgn} \\left ( -3 + 3 +  0.5 \\right ) \\\\\n",
    "= \\textrm{sgn} \\left ( 0.5 \\right ) \\\\\n",
    "= 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Plotten Sie alle 4 Punkte und die Trennebene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = [1, -1]\n",
    "x2 = [-1, 3]\n",
    "y1 = [3, 3]\n",
    "y2 = [-1, 0]\n",
    "plt.scatter(x1, y1, color = \"r\", label=\"- 1\")\n",
    "plt.scatter(x2, y2, color = \"g\", label=\"+ 1\")\n",
    "x_range = np.linspace(-1.5, 3.5, 10)\n",
    "plt.plot(x_range, np.ones(len(x_range)), color=\"b\", linewidth = 2, label=\"Diskriminanzfunktion\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Nehmen Sie an, dass sich im Datensatz ein weiterer Punkt $ \\mathbf{x}=\\begin{bmatrix} 0 \\\\ 3 \\\\ \\end{bmatrix} $ mit Klasse $ \\mathbf{y}=+1 $ befindet. Was ist das Problem? Wie kann es gelöst werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für $\\mathbf{x}=\\begin{bmatrix} 0 \\\\ 3 \\\\ \\end{bmatrix}$ gilt:\n",
    "\n",
    "$ \\textrm{sgn}\n",
    "\\left(h\\left(\n",
    "\\begin{pmatrix}\n",
    "0\\\\\n",
    "3\\\\\n",
    "\\end{pmatrix}\\right)\\right) = -1\n",
    "$.\n",
    "\n",
    "Dieser Punkt wird also falsch klassifiziert.\n",
    "\n",
    "Die Klassen sind dann nicht mehr im 2-dimensionalen Raum linear trennbar.\n",
    "\n",
    "Das Problem kann gelöst werden, indem die Daten in eine höhere Dimension transformiert werden, in der sie wieder linear trennbar sind. In diesem Beispiel könnten die Klassen getrennt werden, indem man sie auf einer Z-Achse zueinander verschiebt). Alternativ kann auch ein Kernel-Trick angewendet werden, um die Hyperebene nur implizit in einem höherdimensionalen Raum zu berechnen, ohne die Daten explizit zu transformieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aufgabe 2: Kernel-Trick \n",
    "\n",
    "In der vorigen Aufgabe wurden SVMs mit linearem Kernel $k_{linear}(x,y) = \\langle  x,y \\rangle = x^Ty $ betrachtet. Betrachten Sie nun einen polynomialen Kernel $ k_{q} = (x^Ty)^2 $. Dabei sind $x, y \\in \\mathbb{R}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Was ist der Vorteil einer Kernelfunktion gegenüber dem Skalarprodukt im höherdimensionalen Raum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Berechnung ist günstiger mit der Kernelfunktion als das Skalarprodukt im höherimensionalen Raum zu berechnen (siehe c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Leiten Sie von Kernel $ k_{q} = (x^Ty)^2 $ ausgehend die Transformationsfunktion $\\phi(x)$ her \n",
    "und geben Sie $ \\langle  \\phi(x),\\phi(y) \\rangle $ an. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit $x=(x_1,x_2),y=(y_1,y_2)\\in \\mathbb{R}^2$ gilt:\n",
    "\n",
    "\\begin{align}\n",
    "K(x,y) &= (x_1y_1 + x_2y_2)^2\\\\\n",
    "&= (x_1y_1)^2 + 2x_1y_1x_2y_2 + (x_2y_2)^2\\\\\n",
    "&= x_1^2 y_1^2 + \\sqrt{2}x_1x_2\\sqrt{2}y_1y_2 + x_2^2y_2^2\\\\\n",
    "&= \\langle\\begin{pmatrix}\n",
    "x_1^2\\\\\n",
    "\\sqrt{2}x_1x_2\\\\\n",
    "x_2^2\n",
    "\\end{pmatrix},\n",
    "\\begin{pmatrix}\n",
    "y_1^2\\\\\n",
    "\\sqrt{2}y_1y_2\\\\\n",
    "y_2^2\n",
    "\\end{pmatrix}\\rangle \n",
    "\\end{align}\n",
    "\n",
    "Also ist $\\phi(x) = \\begin{pmatrix}\n",
    "x_1^2\\\\\n",
    "\\sqrt{2}x_1x_2\\\\\n",
    "x_2^2\n",
    "\\end{pmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Zählen Sie die Anzahl der Multiplikationen und Additionen jeweils für die Berechnung von\n",
    "* $(x^Ty)^2$\n",
    "* $\\phi(x)^T\\phi(y)$,\n",
    "wobei die Transformationsfunktion $\\phi$ aus b) benutzt werden soll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $(x^Ty)^2$:\n",
    "\n",
    "  Mit $z = x_1y_1 + x_2y_2$ (2 Multiplikationen, 1 Addition) und $z^2$ $\\Rightarrow$ 3 Multiplikationen, 1 Addition\n",
    "\n",
    "\n",
    "* $\\phi(x)^T\\phi(y)$:\n",
    "\n",
    "  Mit $ x_1^2y_1^2 + \\sqrt{2}x_1x_2\\sqrt{2}y_1y_2 + x_2^2y_2^2 $ (11 Multiplikationen, 2 Additionen)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Aufgabe 3: Backpropagation (bewertet: 0,5+4,5 Punkte)**\n",
    "\n",
    "Der folgende Graph repräsentiert ein einzelnes Neuron eines neuronalen Netzes mit 3-dimensionalem Eingabevektor $x$, lernbaren Gewichten $w$ und **tanh** Aktivierung. Die Ausgabe eines solchen Neurons ist $ \\mathrm{tanh}\\left(\\sum_{i}w_ix_i + b\\right) $. Im Graph ist die Berechung in kleinere Operationen aufgeteilt um die Anwendung des Backpropagation-Algorithmus zu verdeutlichen.\n",
    "\n",
    "![image](tanh_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Führen Sie den Forward-Pass durch. \n",
    "\n",
    "Berechnen Sie also die Werte $\n",
    "f_1, f_2, f_3, f_4, f_5$ und $f_t.\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{align} \n",
    "f_1&=x_0*w_0+x_1*w_1+x_2*w_2+b \\\\\n",
    "   &=2*(-0.75)+3*2+(-1)*(3)-2=-0.5\\\\\n",
    "f_2&=2*f_1=-1   \\\\  \n",
    "f_3&=e^{f_2}=0.36787944\\\\\n",
    "f_4&=f_3+1=1.36787944\\\\\n",
    "f_5&=2/f_4=1.4621171\\\\\n",
    "f_t&=1-f_5=-0.4621171\\\\\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Berechnen Sie den Gradienten für alle Knoten im Graph mittels Backpropagation. \n",
    "\n",
    "Berechnen Sie also die Werte $\n",
    "\\frac{df_t}{dw_0},\n",
    "\\frac{df_t}{dw_1},\n",
    "\\frac{df_t}{dw_2},\n",
    "\\frac{df_t}{dx_0},\n",
    "\\frac{df_t}{dx_1},\n",
    "\\frac{df_t}{dx_2},\n",
    "\\frac{df_t}{db},\n",
    "\\frac{df_t}{df_1},\n",
    "\\frac{df_t}{df_2},\n",
    "\\frac{df_t}{df_3},\n",
    "\\frac{df_t}{df_4},\n",
    "\\frac{df_t}{df_5},$ und $ \\frac{df_t}{df_t}.\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{align}    \n",
    "\\dfrac{df_t}{df_t}&=1 \\\\ \\\\\n",
    "\\dfrac{df_t}{df_5}&=\\dfrac{df_t}{df_t}*\\dfrac{df_t}{df_5}=1*(-1)=-1\\\\ \\\\\n",
    "\\dfrac{df_t}{df_4}&=\\dfrac{df_t}{df_5}*\\dfrac{df_5}{df_4}=(-1)*(-2/(f_4)^2)= 2/1.36787944^2=1.068893290\\\\ \\\\\n",
    "\\dfrac{df_t}{df_3}&=\\dfrac{df_t}{df_4}*\\dfrac{df_4}{df_3}=1.068893290 * 1 = 1.068893290\\\\ \\\\\n",
    "\\dfrac{df_t}{df_2}&=1.068893290 * e^{f_2}= 1.068893290 * e^{-1}=0.393223866  \\\\ \\\\\n",
    "\\dfrac{df_t}{df_1}&=0.393223866*2=0.7864477\\\\ \\\\\n",
    "\\dfrac{df_t}{df_b}&=0.7864477*1 = 0.7864477\\\\ \\\\\n",
    "\\dfrac{df_t}{df_{x_2}}&= 0.7864477*w_2 = 0.7864477*(-1)= -0.7864477\\\\ \\\\\n",
    "\\dfrac{df_t}{df_{w_2}}&=0.7864477*x_2 = 0.7864477*3 = 2.3593432 \\\\ \\\\\n",
    "\\dfrac{df_t}{df_{x_1}}&= 0.7864477*w_1 = 0.7864477*3  =  2.3593432\\\\ \\\\\n",
    "\\dfrac{df_t}{df_{w_1}}&= 0.7864477*x_1 = 0.7864477*2= 1.572895466\\\\ \\\\\n",
    "\\dfrac{df_t}{df_{x_0}}&= 0.7864477*w_0 = 0.7864477*2 =1.572895466\\\\ \\\\\n",
    "\\dfrac{df_t}{df_{w_0}}&= 0.7864477*x_0 =0.7864477*(-0.75) =-0.5898357997\n",
    "\\end{align}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
