{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungszettel 6: Entscheidugnsbäume, K-Nearest Neighbors\n",
    "\n",
    "## Maschinelles Lernen - WiSe 23/24\n",
    "\n",
    "### Abgabe 06.12.2023, 23:55 Uhr\n",
    "\n",
    "*Hinweise:*\n",
    "- Übungsaufgaben **müssen** in Gruppen von 3-4 Personen abgegeben werden. **Einzelabgaben werden nicht korrigiert bzw. bewertet.**\n",
    "- Es wird pro Übungszettel nur eine Aufgabe bewertet, die übrigen Aufgaben dienen zur selbstständigen Vertiefung des Vorlesungsstoffs. Für diese Aufgaben werden nach der Abgabe Musterlösungen bereitgestellt.\n",
    "- Die Lösungen sollen in diesem IPython Notebook realisiert werden, wobei Teilaufgaben und Zwischenergebnisse ausgegeben bzw. visualisiert werden sollen.\n",
    "- Für die Abgabe sollen Sie dieses IPython Notebook und ggf. zugehörige Dateien in ein **Ziparchiv** packen und im Ilias hochladen. Das Ziparchiv soll nach folgendem Muster benannt werden:\n",
    "`UebungXX_Nachname1_Nachname2_Nachname3.zip`, wobei die Nachnamen in alphabetischer Reihenfolge angegeben und Umlaute ggf. ersetzt werden sollen. Bei Nichtbefolgung dieser Vorgabe können Punkte abgezogen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aufgabe 1:  ID3 in Python \n",
    "\n",
    "\n",
    "In dieser Aufgabe soll ein ID3 Entscheidungsbaum programmiert werden. Im Order `ID3` finden Sie Hilfsmethoden und Methoden die noch implementiert werden müssen. Schauen Sie sich den Code in den Dateien `ID3.py` und `utils.py` an. Die Klasse `SplitNode` enthält ein Attribut und Referenzen zu Kindknoten, für jeden möglichen Wert des Attributes einen. Die Klasse `PredictionNode` wird für Blattknoten verwendet und enthält lediglich die Vorhersage für den Pfad vom Wurzelknoten bis zu diesem Blatknoten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Implementieren Sie folgende Methoden:\n",
    "\n",
    "* `entropy` - berechnet die Entropie für eine Liste von Attributwerten, d.h. $ H{(S)} = \\sum_{x \\in X}{-p(x) \\log_{2}p(x)}$, wobei $S$ die aktuelle Menge von Beispielen ist, für die Entropie berechnet wird, $X$ die Menge von Klassen in $S$ und $p(x)$ der Anteil der Klasse $x$ in $S$.\n",
    "* `info_gain` - berechnet den Information Gain für ein Attribut, wenn dieses zum Splitten benutzt wird, er ist definiert als $IG(S, A) = H{(S)} - \\sum_{t \\in T} p(t)H{(t)}$ mit\n",
    "  * $H(S)$ - Entropie der Menge $S$\n",
    "  * $T$ - die Untermengen, die beim Splitten von $S$ mit Attribut $A$ entstehen, sodass $S = \\bigcup_{t \\in T} t$\n",
    "  * $p(t)$ - Anteil der Anzahl von Elementen in $t$ von Elementen in $S$\n",
    "  * $H(t)$ - Entropie der Untermenge $t$\n",
    "* `get_split_attr` - liefert aus einer Liste von Attributen das Attribut mit dem höchsten Information Gain zurück\n",
    "* `build_tree` - Rekursive Methode, die jeweils das beste Attribut zum Splitten auswählt und dann ggf. für die Kindknoten aufgerufen wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Berechnen und visualisieren Sie die Entscheidungsbäume für die Datasets `tennis.csv` und `mushrooms.csv`. Nutzen Sie dazu die Methode `tree_to_dot`, welche eine Graphrepräsentation in DOT erzeugt. Diese kann dann mit GraphViz (https://graphviz.readthedocs.io/en/stable/manual.html) visualisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Implementieren Sie die Methode `predict` die den Entscheidungsbaum traversiert und ein Dictionary mit Attributname als Key und Attributwert als Value erwartet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Wenden Sie die Methode an und Klassifizieren sie folgende Beispiele:\n",
    "\n",
    "* `Outlook=Overcast,Temperature=Hot,Humidity=Normal,Wind=Strong` (`tennis.csv`)\n",
    "* `odor=none, spore-print-color=white, habitat=woods, gill-size=narrow, cap-color=cinnamon` (`mushrooms.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aufgabe 2: Entscheidungsbäume\n",
    "\n",
    "a) Geben Sie zu folgendem Entscheidungsbaum die Partitionierung an. Zeichnen Sie dazu ein Koordinatensystem. Geben Sie den Partitionen Bezeichner, die Sie entsprechend in den Baum übertragen.\n",
    "\n",
    "![Baum](./task2_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Hier können Sie Ihre Lösung in } \\mathrm{L\\!\\!^{{}_{A}} \\!\\!\\!\\!\\!\\;\\; T\\!_{\\displaystyle E} \\! X} \\text{ einfügen...} $$\n",
    "\n",
    "![Bild](https://via.placeholder.com/500x80?text=...oder+ein+Bild+einbinden.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Welche Partition kann man als overfitted bezeichnen? Markieren Sie im Entscheidungsbaum die Knoten oder Teilbäume, die entfernt werden müssen, um Overfitting zu vermeiden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Hier können Sie Ihre Lösung in } \\mathrm{L\\!\\!^{{}_{A}} \\!\\!\\!\\!\\!\\;\\; T\\!_{\\displaystyle E} \\! X} \\text{ einfügen...} $$\n",
    "\n",
    "![Bild](https://via.placeholder.com/500x80?text=...oder+ein+Bild+einbinden.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Was bedeutet die Generalisierungsfähigkeit eines Classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Aufgabe 3: K-Nearest Neighbors und fehlende Werte (3+1,5+0,5 Punkte)\n",
    "\n",
    "Gegeben sei folgende Beispielmenge $V$ mit $ v_i, v_j \\in V $. Dabei ist `PlayTennis` das Klassifikationsattribut:\n",
    "\n",
    "| Day    |Outlook   | Temperature  |Humidity | Wind   | PlayTennis |\n",
    "|--------|----------|--------------|---------|--------|------------|\n",
    "| D1     | Sunny    | 26           | High    | ?      | No         |\n",
    "| D2     | Sunny    | 28           | High    | Strong | No         |\n",
    "| D3     | Overcast | 29           | High    | Weak   | Yes        |\n",
    "| D4     | Rain     | 23           | High    | Weak   | Yes        |\n",
    "| D5     | Rain     | ?            | Normal  | Weak   | Yes        |\n",
    "| D6     | Rain     | 12           | Normal  | Strong | No         |\n",
    "| D7     | Overcast | 8            | ?       | Strong | Yes        |\n",
    "| D8     | Sunny    | 25           | High    | Weak   | No         |\n",
    "| D9     | Sunny    | 18           | Normal  | Weak   | Yes        |\n",
    "| D10    | Rain     | 20           | Normal  | Weak   | Yes        |\n",
    "| D11    | Sunny    | 20           | Normal  | Strong | ?          |\n",
    "| D12    | Overcast | 21           | High    | Strong | Yes        |\n",
    "| D13    | ?        | 26           | Normal  | Weak   | Yes        |\n",
    "| D14    | Rain     | 24           | High    | Strong | No         |\n",
    "| D15    | Sunny    | 23           | Normal  | Weak   | No         |\n",
    "| D16    | Sunny    | 21           | Normal  | Weak   | Yes        |\n",
    "\n",
    "a) Um fehlende Werte zu behandeln, kann man diese einfach auffüllen, indem man die am naheliegendsten Nachbarn zu diesem Beispiel verwendet. Benutzen Sie hierfür 3-NN zum Ausfüllen dieser Werte.\n",
    "\n",
    "* Normieren Sie das numerische Attribut wie folgt:\n",
    "  $$ \\hat{v}_i = \\frac{v_i - \\min v_j}{\\max v_j - \\min v_j}$$\n",
    "  \n",
    "* Überlegen Sie sich eine Distanzfunktion für das numerische Attribut\n",
    "\n",
    "* Benutzen Sie für nominale Attribute die die 0/1-Distanz\n",
    "  $$ d_A(v_1,v_2) = \\begin{cases}\n",
    "      0, & \\text{if}\\ v_1=v_2 \\\\\n",
    "      1, & \\text{if}\\ v_1 \\neq v_2\n",
    "    \\end{cases} \n",
    "  $$\n",
    "  \n",
    "* Benutzen Sie als Distanzfunktion für 3-NN die Manhattan-Distanz auf allen normierten Attributen\n",
    " \n",
    "* Beziehen Sie für das Auffüllen von Werten die Klassifikation der Beispiele mit ein\n",
    "\n",
    "* Überlegen Sie sich, wie sie beim Auffüllen mit fehlenden Attributen in den Nachbarn umgehen\n",
    "\n",
    "* Benutzen Sie beim Berechnen der fehlenden Attribute stets nur die ursprüngliche Beispielmenge (also ohne möglicherweise vorher aufgefüllte Attribute)\n",
    "\n",
    "Verwenden Sie die von Ihnen ausgefüllten Werte auch für die nächsten Aufgaben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "start\n",
      "day 13 is missing : Outlook\n",
      "nearest_values:  ['Sunny', 'Rain', 'Sunny']\n",
      "['Sunny', 'Rain', 'Sunny']\n",
      "start\n",
      "day 5 is missing : Temperature\n",
      "nearest_values:  [20.0, 18.0, 21.0]\n",
      "start\n",
      "day 7 is missing : Humidity\n",
      "nearest_values:  ['High', 'High', 'Normal']\n",
      "['High', 'High', 'Normal']\n",
      "start\n",
      "day 1 is missing : Wind\n",
      "nearest_values:  ['Strong', 'Strong', 'Weak']\n",
      "['Strong', 'Strong', 'Weak']\n",
      "start\n",
      "day 11 is missing : PlayTennis\n",
      "nearest_values:  ['Yes', 'Yes', 'No']\n",
      "['Yes', 'Yes', 'No']\n",
      "After:\n",
      "    Day   Outlook  Temperature Humidity    Wind PlayTennis\n",
      "0    D1     Sunny    26.000000     High  Strong         No\n",
      "1    D2     Sunny    28.000000     High  Strong         No\n",
      "2    D3  Overcast    29.000000     High    Weak        Yes\n",
      "3    D4      Rain    23.000000     High    Weak        Yes\n",
      "4    D5      Rain    19.666667   Normal    Weak        Yes\n",
      "5    D6      Rain    12.000000   Normal  Strong         No\n",
      "6    D7  Overcast     8.000000     High  Strong        Yes\n",
      "7    D8     Sunny    25.000000     High    Weak         No\n",
      "8    D9     Sunny    18.000000   Normal    Weak        Yes\n",
      "9   D10      Rain    20.000000   Normal    Weak        Yes\n",
      "10  D11     Sunny    20.000000   Normal  Strong        Yes\n",
      "11  D12  Overcast    21.000000     High  Strong        Yes\n",
      "12  D13     Sunny    26.000000   Normal    Weak        Yes\n",
      "13  D14      Rain    24.000000     High  Strong         No\n",
      "14  D15     Sunny    23.000000   Normal    Weak         No\n",
      "15  D16     Sunny    21.000000   Normal    Weak        Yes\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Daten der Beispielmenge\n",
    "data = {\n",
    "    \"Day\": [\"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"D10\", \"D11\", \"D12\", \"D13\", \"D14\", \"D15\", \"D16\"],\n",
    "    \"Outlook\": [\"Sunny\", \"Sunny\", \"Overcast\", \"Rain\", \"Rain\", \"Rain\", \"Overcast\", \"Sunny\", \"Sunny\", \"Rain\", \"Sunny\", \"Overcast\", \"Unknown\", \"Rain\", \"Sunny\", \"Sunny\"],\n",
    "    \"Temperature\": [26, 28, 29, 23, np.nan, 12, 8, 25, 18, 20, 20, 21, 26, 24, 23, 21],\n",
    "    \"Humidity\": [\"High\", \"High\", \"High\", \"High\", \"Normal\", \"Normal\", \"Unknown\", \"High\", \"Normal\", \"Normal\", \"Normal\", \"High\", \"Normal\", \"High\", \"Normal\", \"Normal\"],\n",
    "    \"Wind\": [\"Unknown\", \"Strong\", \"Weak\", \"Weak\", \"Weak\", \"Strong\", \"Strong\", \"Weak\", \"Weak\", \"Weak\", \"Strong\", \"Strong\", \"Weak\", \"Strong\", \"Weak\", \"Weak\"],\n",
    "    \"PlayTennis\": [\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Unknown\", \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\"]\n",
    "}\n",
    "\n",
    "#create dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#find max temparetur\n",
    "maxTemp = df[\"Temperature\"].max()\n",
    "#find min temparetur\n",
    "minTemp = df[\"Temperature\"].min()\n",
    "\n",
    "#normalize temparetur\n",
    "df[\"Temperature_norm\"] = (df[\"Temperature\"] - minTemp) / (maxTemp - minTemp)\n",
    "print('Before:')\n",
    "\n",
    "def cal_nominal_value(v1,v2):\n",
    "    if(v1 == v2):\n",
    "        return 0\n",
    "    elif(v1 != v2):\n",
    "        return 1\n",
    "    \n",
    "#funktion zur berechnung der manhattan distance\n",
    "def temp_norm_cal(v1, v2):\n",
    "    return abs(v1 - v2)\n",
    "\n",
    "# Funktion zum Auffüllen der fehlenden Werte mit 3-NN\n",
    "def fill_missing_value(df, attribute, k):\n",
    "    print('start')\n",
    "    #for each df columns\n",
    "    for i, day in df.iterrows():\n",
    "        #if value is missing\n",
    "        if pd.isna(day[attribute]) or day[attribute] == 'Unknown':\n",
    "            print('day', (i+1), 'is missing :',attribute)\n",
    "            distances = []\n",
    "            for j, other_day in df.iterrows():\n",
    "                if i != j and not (pd.isna(other_day[attribute]) or other_day[attribute] == 'Unknown'):\n",
    "                    dist = 0\n",
    "                    if(attribute == \"Outlook\"):\n",
    "                        dist += temp_norm_cal(day['Temperature_norm'], other_day['Temperature_norm'])\n",
    "                        dist += cal_nominal_value(day['Humidity'], other_day['Humidity'])\n",
    "                        dist += cal_nominal_value(day['Wind'], other_day['Wind'])\n",
    "                        dist += cal_nominal_value(day['PlayTennis'], other_day['PlayTennis'])\n",
    "                    if(attribute == \"Temperature\"): \n",
    "                        dist += cal_nominal_value(day['Outlook'], other_day['Outlook'])\n",
    "                        dist += cal_nominal_value(day['Humidity'], other_day['Humidity'])\n",
    "                        dist += cal_nominal_value(day['Wind'], other_day['Wind'])\n",
    "                        dist += cal_nominal_value(day['PlayTennis'], other_day['PlayTennis'])    \n",
    "                    if(attribute == \"Humidity\"):\n",
    "                        dist += temp_norm_cal(day['Temperature_norm'], other_day['Temperature_norm'])\n",
    "                        dist += cal_nominal_value(day['Outlook'], other_day['Outlook'])\n",
    "                        dist += cal_nominal_value(day['Wind'], other_day['Wind'])\n",
    "                        dist += cal_nominal_value(day['PlayTennis'], other_day['PlayTennis'])\n",
    "                    if(attribute == \"Wind\"):    \n",
    "                        dist += temp_norm_cal(day['Temperature_norm'], other_day['Temperature_norm'])\n",
    "                        dist += cal_nominal_value(day['Outlook'], other_day['Outlook'])\n",
    "                        dist += cal_nominal_value(day['Humidity'], other_day['Humidity'])\n",
    "                        dist += cal_nominal_value(day['PlayTennis'], other_day['PlayTennis'])\n",
    "                    if(attribute == \"PlayTennis\"):    \n",
    "                        dist += temp_norm_cal(day['Temperature_norm'], other_day['Temperature_norm'])\n",
    "                        dist += cal_nominal_value(day['Outlook'], other_day['Outlook'])\n",
    "                        dist += cal_nominal_value(day['Humidity'], other_day['Humidity'])\n",
    "                        dist += cal_nominal_value(day['Wind'], other_day['Wind'])\n",
    "                    distances.append((dist, other_day[attribute]))\n",
    "            distances.sort()\n",
    "            nearest_values = [val for _, val in distances[:k]]\n",
    "            #print(nearest_values)\n",
    "            print('nearest_values: ', nearest_values)\n",
    "            #if nearest_values a list of numbers\n",
    "            if all(isinstance(x, (int,float)) for x in nearest_values):\n",
    "                df.at[i, attribute] = sum(nearest_values) / k\n",
    "                continue\n",
    "            else:\n",
    "                print(nearest_values)\n",
    "                df.at[i, attribute] = max(set(nearest_values), key=nearest_values.count)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "#fill missing values\n",
    "\n",
    "attributes = ['Outlook', 'Temperature', 'Humidity', 'Wind', 'PlayTennis']\n",
    "\n",
    "for attribute in attributes:\n",
    "    df = fill_missing_value(df, attribute, 3)\n",
    "\n",
    "#remove temparetur_norm\n",
    "df = df.drop(columns=['Temperature_norm'])\n",
    "print('After:')\n",
    "print(df)\n",
    "\n",
    "if ['Sunny', 'Rain', 'Sunny'] :\n",
    "    print('Yes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Benutzen Sie für die Berechnung von $k$-NN die gleichen Eckdaten wie in der vorherigen Aufgabe (Normierung für numerische Attribute, 0/1-Distanz für nominale Attribute und die Manhattan Distanz). \n",
    "\n",
    "Berechnen Sie für das folgende Beispiel die Distanz zu jedem Datenpunkt und klassifizieren Sie das Beispiel mit 1-NN:\n",
    "\n",
    "* **D17**: `Outlook=Sunny, Temperature=23, Humidity=High, Wind=Strong`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Testen Sie nun verschiedene $k$. Für welches k ändert sich die Klassifikation gegenüber $k = 1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
