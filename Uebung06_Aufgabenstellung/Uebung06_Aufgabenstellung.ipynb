{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungszettel 6: Entscheidugnsbäume, K-Nearest Neighbors\n",
    "\n",
    "## Maschinelles Lernen - WiSe 23/24\n",
    "\n",
    "### Abgabe 06.12.2023, 23:55 Uhr\n",
    "\n",
    "*Hinweise:*\n",
    "- Übungsaufgaben **müssen** in Gruppen von 3-4 Personen abgegeben werden. **Einzelabgaben werden nicht korrigiert bzw. bewertet.**\n",
    "- Es wird pro Übungszettel nur eine Aufgabe bewertet, die übrigen Aufgaben dienen zur selbstständigen Vertiefung des Vorlesungsstoffs. Für diese Aufgaben werden nach der Abgabe Musterlösungen bereitgestellt.\n",
    "- Die Lösungen sollen in diesem IPython Notebook realisiert werden, wobei Teilaufgaben und Zwischenergebnisse ausgegeben bzw. visualisiert werden sollen.\n",
    "- Für die Abgabe sollen Sie dieses IPython Notebook und ggf. zugehörige Dateien in ein **Ziparchiv** packen und im Ilias hochladen. Das Ziparchiv soll nach folgendem Muster benannt werden:\n",
    "`UebungXX_Nachname1_Nachname2_Nachname3.zip`, wobei die Nachnamen in alphabetischer Reihenfolge angegeben und Umlaute ggf. ersetzt werden sollen. Bei Nichtbefolgung dieser Vorgabe können Punkte abgezogen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aufgabe 1:  ID3 in Python \n",
    "\n",
    "\n",
    "In dieser Aufgabe soll ein ID3 Entscheidungsbaum programmiert werden. Im Order `ID3` finden Sie Hilfsmethoden und Methoden die noch implementiert werden müssen. Schauen Sie sich den Code in den Dateien `ID3.py` und `utils.py` an. Die Klasse `SplitNode` enthält ein Attribut und Referenzen zu Kindknoten, für jeden möglichen Wert des Attributes einen. Die Klasse `PredictionNode` wird für Blattknoten verwendet und enthält lediglich die Vorhersage für den Pfad vom Wurzelknoten bis zu diesem Blatknoten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Implementieren Sie folgende Methoden:\n",
    "\n",
    "* `entropy` - berechnet die Entropie für eine Liste von Attributwerten, d.h. $ H{(S)} = \\sum_{x \\in X}{-p(x) \\log_{2}p(x)}$, wobei $S$ die aktuelle Menge von Beispielen ist, für die Entropie berechnet wird, $X$ die Menge von Klassen in $S$ und $p(x)$ der Anteil der Klasse $x$ in $S$.\n",
    "* `info_gain` - berechnet den Information Gain für ein Attribut, wenn dieses zum Splitten benutzt wird, er ist definiert als $IG(S, A) = H{(S)} - \\sum_{t \\in T} p(t)H{(t)}$ mit\n",
    "  * $H(S)$ - Entropie der Menge $S$\n",
    "  * $T$ - die Untermengen, die beim Splitten von $S$ mit Attribut $A$ entstehen, sodass $S = \\bigcup_{t \\in T} t$\n",
    "  * $p(t)$ - Anteil der Anzahl von Elementen in $t$ von Elementen in $S$\n",
    "  * $H(t)$ - Entropie der Untermenge $t$\n",
    "* `get_split_attr` - liefert aus einer Liste von Attributen das Attribut mit dem höchsten Information Gain zurück\n",
    "* `build_tree` - Rekursive Methode, die jeweils das beste Attribut zum Splitten auswählt und dann ggf. für die Kindknoten aufgerufen wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Berechnen und visualisieren Sie die Entscheidungsbäume für die Datasets `tennis.csv` und `mushrooms.csv`. Nutzen Sie dazu die Methode `tree_to_dot`, welche eine Graphrepräsentation in DOT erzeugt. Diese kann dann mit GraphViz (https://graphviz.readthedocs.io/en/stable/manual.html) visualisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Implementieren Sie die Methode `predict` die den Entscheidungsbaum traversiert und ein Dictionary mit Attributname als Key und Attributwert als Value erwartet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Wenden Sie die Methode an und Klassifizieren sie folgende Beispiele:\n",
    "\n",
    "* `Outlook=Overcast,Temperature=Hot,Humidity=Normal,Wind=Strong` (`tennis.csv`)\n",
    "* `odor=none, spore-print-color=white, habitat=woods, gill-size=narrow, cap-color=cinnamon` (`mushrooms.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aufgabe 2: Entscheidungsbäume\n",
    "\n",
    "a) Geben Sie zu folgendem Entscheidungsbaum die Partitionierung an. Zeichnen Sie dazu ein Koordinatensystem. Geben Sie den Partitionen Bezeichner, die Sie entsprechend in den Baum übertragen.\n",
    "\n",
    "![Baum](./task2_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Hier können Sie Ihre Lösung in } \\mathrm{L\\!\\!^{{}_{A}} \\!\\!\\!\\!\\!\\;\\; T\\!_{\\displaystyle E} \\! X} \\text{ einfügen...} $$\n",
    "\n",
    "![Bild](https://via.placeholder.com/500x80?text=...oder+ein+Bild+einbinden.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Welche Partition kann man als overfitted bezeichnen? Markieren Sie im Entscheidungsbaum die Knoten oder Teilbäume, die entfernt werden müssen, um Overfitting zu vermeiden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Hier können Sie Ihre Lösung in } \\mathrm{L\\!\\!^{{}_{A}} \\!\\!\\!\\!\\!\\;\\; T\\!_{\\displaystyle E} \\! X} \\text{ einfügen...} $$\n",
    "\n",
    "![Bild](https://via.placeholder.com/500x80?text=...oder+ein+Bild+einbinden.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Was bedeutet die Generalisierungsfähigkeit eines Classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Aufgabe 3: K-Nearest Neighbors und fehlende Werte (3+1,5+0,5 Punkte)\n",
    "\n",
    "Gegeben sei folgende Beispielmenge $V$ mit $ v_i, v_j \\in V $. Dabei ist `PlayTennis` das Klassifikationsattribut:\n",
    "\n",
    "| Day    |Outlook   | Temperature  |Humidity | Wind   | PlayTennis |\n",
    "|--------|----------|--------------|---------|--------|------------|\n",
    "| D1     | Sunny    | 26           | High    | ?      | No         |\n",
    "| D2     | Sunny    | 28           | High    | Strong | No         |\n",
    "| D3     | Overcast | 29           | High    | Weak   | Yes        |\n",
    "| D4     | Rain     | 23           | High    | Weak   | Yes        |\n",
    "| D5     | Rain     | ?            | Normal  | Weak   | Yes        |\n",
    "| D6     | Rain     | 12           | Normal  | Strong | No         |\n",
    "| D7     | Overcast | 8            | ?       | Strong | Yes        |\n",
    "| D8     | Sunny    | 25           | High    | Weak   | No         |\n",
    "| D9     | Sunny    | 18           | Normal  | Weak   | Yes        |\n",
    "| D10    | Rain     | 20           | Normal  | Weak   | Yes        |\n",
    "| D11    | Sunny    | 20           | Normal  | Strong | ?          |\n",
    "| D12    | Overcast | 21           | High    | Strong | Yes        |\n",
    "| D13    | ?        | 26           | Normal  | Weak   | Yes        |\n",
    "| D14    | Rain     | 24           | High    | Strong | No         |\n",
    "| D15    | Sunny    | 23           | Normal  | Weak   | No         |\n",
    "| D16    | Sunny    | 21           | Normal  | Weak   | Yes        |\n",
    "\n",
    "a) Um fehlende Werte zu behandeln, kann man diese einfach auffüllen, indem man die am naheliegendsten Nachbarn zu diesem Beispiel verwendet. Benutzen Sie hierfür 3-NN zum Ausfüllen dieser Werte.\n",
    "\n",
    "* Normieren Sie das numerische Attribut wie folgt:\n",
    "  $$ \\hat{v}_i = \\frac{v_i - \\min v_j}{\\max v_j - \\min v_j}$$\n",
    "  \n",
    "* Überlegen Sie sich eine Distanzfunktion für das numerische Attribut\n",
    "\n",
    "* Benutzen Sie für nominale Attribute die die 0/1-Distanz\n",
    "  $$ d_A(v_1,v_2) = \\begin{cases}\n",
    "      0, & \\text{if}\\ v_1=v_2 \\\\\n",
    "      1, & \\text{if}\\ v_1 \\neq v_2\n",
    "    \\end{cases} \n",
    "  $$\n",
    "  \n",
    "* Benutzen Sie als Distanzfunktion für 3-NN die Manhattan-Distanz auf allen normierten Attributen\n",
    " \n",
    "* Beziehen Sie für das Auffüllen von Werten die Klassifikation der Beispiele mit ein\n",
    "\n",
    "* Überlegen Sie sich, wie sie beim Auffüllen mit fehlenden Attributen in den Nachbarn umgehen\n",
    "\n",
    "* Benutzen Sie beim Berechnen der fehlenden Attribute stets nur die ursprüngliche Beispielmenge (also ohne möglicherweise vorher aufgefüllte Attribute)\n",
    "\n",
    "Verwenden Sie die von Ihnen ausgefüllten Werte auch für die nächsten Aufgaben. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Benutzen Sie für die Berechnung von $k$-NN die gleichen Eckdaten wie in der vorherigen Aufgabe (Normierung für numerische Attribute, 0/1-Distanz für nominale Attribute und die Manhattan Distanz). \n",
    "\n",
    "Berechnen Sie für das folgende Beispiel die Distanz zu jedem Datenpunkt und klassifizieren Sie das Beispiel mit 1-NN:\n",
    "\n",
    "* **D17**: `Outlook=Sunny, Temperature=23, Humidity=High, Wind=Strong`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Testen Sie nun verschiedene $k$. Für welches k ändert sich die Klassifikation gegenüber $k = 1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
